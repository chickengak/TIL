{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85772a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ▶ tf.keras.applications.vgg16 \"\"\"\n",
    "'''\n",
    "tf.keras.applications 에 포함된 모델들은 사전에 학습된(pre-trained) 가중치를 가진 유명한 딥러닝 모델의 구현체다.\n",
    "VGG, ResNet, Inception, MobileNet 등의 다양한 유명한 아키텍처를 제공하며, 이들 모델은 대규모 이미지 데이터셋(주로 ImageNet)에서 미리 학습되었다.\n",
    "모델을 로드할 때 weights 파라미터를 'imagenet'으로 설정하면 사전에 학습된 가중치를 사용하여 모델을 로드할 수 있다. 가중치를 로드하지 않으려면 weights=None으로 설정하면 된다.\n",
    "\n",
    "그 중, vgg16을 가져와서 실습해 볼 예정이다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0579b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ▶ 모델 객체, 레이어 속성 \"\"\"\n",
    "'''\n",
    " 1. 이름으로 레이어 객체 리턴: model.get_layer(name, index).name\n",
    " 2. 인덱스로 레이어 객체 리턴: model.get_layer(name, index) ;  model.layers[index].name ;  model.layers\n",
    " 3. 레이어 객체의 속성 및 메소드: tf.keras.layers.Layer의 하위 클래스들을 확인\n",
    " 4. 조건을 만족하는 레이어 오브젝트 리턴, 설정 값 변경\n",
    " 5. 모델이나 레이어의 가중치(커널의 가중치)나 바이어스 등의 파라미터 값을 리턴\n",
    "     5-1. 레이어 파라미터(가중치, 바이어스): get_weights(), .weights 속성, trainable_weights, non_trainable_weights, kernel, bias 속성\n",
    "     5-2. 모델: get_weights(), weights 속성\n",
    "     5-3. CNN 필터(커널)의 가중치 및 시각화\n",
    "     \n",
    " * 전이학습을 통해서 사용자 모델을 만들고 콜백 핸들러 함수 및 객체를 통해서 튜닝을 할 수 있다.\n",
    " CNN, RNN, LSTM_자연어, AE -> (GAN, UNET)\n",
    " \n",
    " \n",
    " tf.keras.applications.vgg16.VGG16(\n",
    "    include_top=True,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a622cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ALT\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ALT\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ALT\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138357544 (527.79 MB)\n",
      "Trainable params: 138357544 (527.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1. 학습된 모델인 VGG16 가져오기\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "model = VGG16()#( weights = None )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18846c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001E6D514C750> block4_conv1\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001E6D514C750> block4_conv1\n",
      "True\n",
      "block4_conv1\n"
     ]
    }
   ],
   "source": [
    "# 1-2.  모델의 name이나 인덱스로 레이어 오브젝트를  get_layer()로 리턴  \n",
    "res1 = model.get_layer('block4_conv1')\n",
    "print(res, res.name)\n",
    "\n",
    "res2 = model.get_layer(index=11)\n",
    "print(res, res.name)\n",
    "print(res1 is res2)\n",
    "\n",
    "print(model.get_layer(index = -12).name)  # 음수 인덱스 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0609077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.engine.input_layer.InputLayer object at 0x000001E6CA176410>\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001E6D5057010>\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001E6D514D350>\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001E6D506B8D0>\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001E6D514D890>\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001E6D5054B10>\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001E6D2A06850>\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001E6D0421B10>\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001E6D516C690>\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001E6D506A790>\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001E6CFFBED90>\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001E6D514C750>\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001E6D5079690>\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001E6D5055390>\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001E6D2A77C90>\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001E6D4F29DD0>\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001E6D51CC2D0>\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001E6D5043C10>\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001E6D516E410>\n",
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x000001E6D4EC1050>\n",
      "<keras.src.layers.core.dense.Dense object at 0x000001E6D51CCB10>\n",
      "<keras.src.layers.core.dense.Dense object at 0x000001E6D514DD90>\n",
      "<keras.src.layers.core.dense.Dense object at 0x000001E6D5079ED0>\n",
      "\n",
      "<class 'list'>\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001E6D514C750>\n",
      "predictions\n"
     ]
    }
   ],
   "source": [
    "# 1-3.  모델이 가진 레이어 객체들을 보자. model.layers\n",
    "print(*model.layers, sep='\\n', end='\\n\\n')\n",
    "\n",
    "print(type(model.layers))   # model.layers가 list이기 때문에, 아래처럼 인덱싱 가능.\n",
    "print(model.layers[11])\n",
    "print(model.layers[-1].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71990a63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001E6D506B8D0>\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001E6D2A06850>\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001E6CFFBED90>\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001E6D2A77C90>\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001E6D516E410>\n",
      "<keras.src.layers.core.dense.Dense object at 0x000001E6D51CCB10>\n",
      "<keras.src.layers.core.dense.Dense object at 0x000001E6D514DD90>\n",
      "<keras.src.layers.core.dense.Dense object at 0x000001E6D5079ED0>\n"
     ]
    }
   ],
   "source": [
    "# 1-4. 특정 레이어만 추출하기\n",
    "my_pools = model.layers[-5:]\n",
    "my_pools = [layer for layer in model.layers if 'pool' in layer.name]\n",
    "my_pools = [layer for layer in model.layers if isinstance(layer, tf.keras.layers.MaxPooling2D)]\n",
    "my_pools = [layer for layer in model.layers if isinstance(layer, (tf.keras.layers.MaxPooling2D, tf.keras.layers.Dense))]\n",
    "print(*my_pools, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a3bf46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5be7f8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001E6D5057010>\n",
      "True\n",
      "True\n",
      "\n",
      "1792\n",
      "False\n",
      "False\n",
      "\n",
      "False\n",
      "new_name_layer01\n"
     ]
    }
   ],
   "source": [
    "# 2. 레이어 객체의 속성 및 메소드를 확인  \n",
    "# 2-1. 레이어 인스턴스 확인\n",
    "layer01 = model.get_layer(index =1)\n",
    "print(layer01)\n",
    "print(isinstance(layer01, tf.keras.layers.Layer ))\n",
    "print(isinstance(layer01, tf.keras.layers.Conv2D ) , end='\\n\\n')\n",
    "\n",
    "# 2-2. 파라미터 수 리턴  count_params()\n",
    "print(layer01.count_params())\n",
    "\n",
    "# 2-3. trainable 속성 바꾸기\n",
    "' 학습이 끝난 모델을 이용한 전이 학습에서 원하는 레이어만 학습 유무를 지정할 때, 사용함. '\n",
    "print(layer01.trainable)\n",
    "layer01.trainable = False\n",
    "print(layer01.trainable     , end='\\n\\n')\n",
    "\n",
    "# 2-4. 원하는 레이어들만 trainable 속성 바꾸기\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "        layer.trainable = False\n",
    "print(model.layers[2].trainable)\n",
    "\n",
    "# 2-5. 레이어 이름 변경도 가능. (한데 할 이유가?)\n",
    "layer01._name = 'new_name_layer01'\n",
    "print(layer01.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41b97175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " L0_conv2d (Conv2D)          (None, 10, 10, 1)         10        \n",
      "                                                                 \n",
      " L1_flatten (Flatten)        (None, 100)               0         \n",
      "                                                                 \n",
      " L2_dense (Dense)            (None, 10)                1000      \n",
      "                                                                 \n",
      " L3_dense (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1)                 4         \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1025 (4.00 KB)\n",
      "Trainable params: 1023 (4.00 KB)\n",
      "Non-trainable params: 2 (8.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 3. 임의의모델을 선언하자    Conv2D  ->Flatten -> Dense -> Dense -> BatchNormalization  \n",
    "model  = tf.keras.Sequential ([ \n",
    "    tf.keras.layers.Conv2D (1,(3,3), padding='same', name='L0_conv2d' ,  input_shape=(10,10,1)),\n",
    "    tf.keras.layers.Flatten ( name='L1_flatten' ),\n",
    "    tf.keras.layers.Dense ( 10 , name='L2_dense' , use_bias = False ) , \n",
    "    tf.keras.layers.Dense ( 1 , name='L3_dense' ) ,\n",
    "    tf.keras.layers.BatchNormalization()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ddcbbccd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 2\n",
      "[array([[ 0.6960506 ],\n",
      "       [-0.39610294],\n",
      "       [ 0.43388206],\n",
      "       [ 0.12455618],\n",
      "       [ 0.38311416],\n",
      "       [ 0.15438235],\n",
      "       [ 0.7262543 ],\n",
      "       [ 0.6164519 ],\n",
      "       [ 0.2885961 ],\n",
      "       [ 0.52117056]], dtype=float32), array([0.], dtype=float32)]\n",
      "\n",
      "가중치  : (10, 1) \n",
      " [[ 0.6960506 ]\n",
      " [-0.39610294]\n",
      " [ 0.43388206]\n",
      " [ 0.12455618]\n",
      " [ 0.38311416]\n",
      " [ 0.15438235]\n",
      " [ 0.7262543 ]\n",
      " [ 0.6164519 ]\n",
      " [ 0.2885961 ]\n",
      " [ 0.52117056]]\n",
      "바이어스 : [0.]\n"
     ]
    }
   ],
   "source": [
    "# 3-1. 모델의 레이어 파라미터(가중치, 바이어스) 리턴을 받자      get_weights()    \n",
    "layer02 = model.layers[3]\n",
    "print( type(layer02.get_weights()) , len(layer02.get_weights()))\n",
    "print(layer02.get_weights(),      end='\\n\\n')   # get_weights()를 해본 결과 [커널의 가중치, 바이어스 값]이 리턴됨.  -> 현재 가중치는 무작위 초기값을 가진다. \n",
    "print('가중치  :', layer02.get_weights()[0].shape, '\\n', layer02.get_weights()[0] )\n",
    "print('바이어스 :', layer02.get_weights()[1] )\n",
    "# 바로 위에서  L3_dense (Dense) 레이어는 파라미터 11개로 나왔다. 이는 10개의 weight와 1개의 bias 파라미터들의 합이었음을 확인 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c2088dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'L3_dense/kernel:0' shape=(10, 1) dtype=float32, numpy=\n",
      "array([[ 0.6960506 ],\n",
      "       [-0.39610294],\n",
      "       [ 0.43388206],\n",
      "       [ 0.12455618],\n",
      "       [ 0.38311416],\n",
      "       [ 0.15438235],\n",
      "       [ 0.7262543 ],\n",
      "       [ 0.6164519 ],\n",
      "       [ 0.2885961 ],\n",
      "       [ 0.52117056]], dtype=float32)>\n",
      "<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>\n",
      "---------------------\n",
      "L3_dense/kernel:0\n",
      "(10, 1)\n",
      "L3_dense/bias:0\n",
      "(1,)\n",
      "---------------------\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 3-2. layer02.weights   -> list -> 각 속성은  ResourceVariable 리턴  <- tf.Variable name, shape속성등을 가진다.  \n",
    "print(layer02.weights[0])\n",
    "print(type(layer02.weights[0]) ) # ResourceVariable\n",
    "print('---------------------')\n",
    "print(layer02.weights[0].name ) \n",
    "print(layer02.weights[0].shape) \n",
    "print(layer02.weights[1].name ) \n",
    "print(layer02.weights[1].shape) \n",
    "print('---------------------')\n",
    "print(layer02.weights[0] is layer02.kernel)    # .kernel과 같다.\n",
    "print(layer02.weights[1] is layer02.bias)      # .bias와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2f0ebb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L0_conv2d \t 2\n",
      "L1_flatten \t 0\n",
      "L2_dense \t 1\n",
      "L3_dense \t 2\n",
      "batch_normalization \t 4\n"
     ]
    }
   ],
   "source": [
    "# 3-3 전체 레이어의 get_weights()  가 리턴하는 요소 수를 출력 해보자.  \n",
    "for layer in model.layers:\n",
    "    print(f'{layer.name } \\t {len(layer.get_weights())}')\n",
    "# 각 레이어마다 다른 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "04038392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============\n",
      "L0_conv2d/kernel:0 \t (3, 3, 1, 1)\n",
      "L0_conv2d/bias:0 \t (1,)\n",
      "============\n",
      "============\n",
      "L2_dense/kernel:0 \t (100, 10)\n",
      "============\n",
      "L3_dense/kernel:0 \t (10, 1)\n",
      "L3_dense/bias:0 \t (1,)\n",
      "============\n",
      "batch_normalization/gamma:0 \t (1,)\n",
      "batch_normalization/beta:0 \t (1,)\n",
      "batch_normalization/moving_mean:0 \t (1,)\n",
      "batch_normalization/moving_variance:0 \t (1,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-4. weights속성을 이용해서 각 레이어의 커널과 bias를 출력\n",
    "for layer in model.layers:\n",
    "    print('============')\n",
    "    for weight in layer.weights:\n",
    "        print(f\"{weight.name} \\t {weight.shape}\")\n",
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7db8a9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization\tTrue\n",
      "batch_normalization/gamma:0 \t (1,)\n",
      "batch_normalization/beta:0 \t (1,)\n",
      "batch_normalization/moving_mean:0 \t (1,)\n",
      "batch_normalization/moving_variance:0 \t (1,)\n"
     ]
    }
   ],
   "source": [
    "# 4. BatchNormalization()는 trainable=True 해도 non_trainable_weights 해당하는 파라미터가 존재한다.\n",
    "\n",
    "print(model.layers[4].name, model.layers[4].trainable   ,sep='\\t')\n",
    "\n",
    "for weight in model.layers[4].trainable_weights:\n",
    "    print(weight.name , \"\\t\", weight.shape)\n",
    "\n",
    "for weight in model.layers[4].non_trainable_weights:\n",
    "    print(weight.name , \"\\t\", weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c3da26fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_7 (Sequential)   (None, 10)                101110    \n",
      "                                                                 \n",
      " L_out_01 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101121 (395.00 KB)\n",
      "Trainable params: 101121 (395.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " L_in_00 (Dense)             (None, 100)               100100    \n",
      "                                                                 \n",
      " L_in_01 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101110 (394.96 KB)\n",
      "Trainable params: 101110 (394.96 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "6 6\n",
      "L_in_00/kernel:0  \t(1000, 100)\n",
      "L_in_00/bias:0  \t(100,)\n",
      "L_in_01/kernel:0  \t(100, 10)\n",
      "L_in_01/bias:0  \t(10,)\n",
      "L_out_01/kernel:0  \t(10, 1)\n",
      "L_out_01/bias:0  \t(1,)\n"
     ]
    }
   ],
   "source": [
    "# 5. 중첩 모델. 모든 모델은 레이어의 하위 클래스이기 때문에, 모델을 하나의 레이어로 선언할 수 있다. \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "inner_model = Sequential([ \n",
    "    Dense(100, name='L_in_00', input_shape=(1000, )),\n",
    "    Dense(10, name='L_in_01')\n",
    "]) \n",
    "\n",
    "outer_model = Sequential( [\n",
    "    inner_model,\n",
    "    Dense(1, name='L_out_01')     \n",
    "]) \n",
    "\n",
    "\n",
    "outer_model.summary()\n",
    "outer_model.layers[0].summary()\n",
    "print()\n",
    "print(len (outer_model.weights) , len (outer_model.get_weights()) ) # 6, 6 \n",
    "\n",
    "for weight in outer_model.weights:\n",
    "    print(weight.name, weight.shape   ,sep='  \\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3820807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c692f48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9fe8dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54e84a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 데이터 로드  \n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "#2 데이터 축소   : [ : 1000] 학습용 데이터 1000,  테스트 500개  \n",
    "train_images = train_images[:1000] \n",
    "test_images = test_images[:500]\n",
    "train_labels = to_categorical(train_labels[:1000], 10)\n",
    "test_labels = to_categorical(test_labels[:500], 10)\n",
    "\n",
    "#3  ResNet50  모델 사용, 전체  레이어 동결\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "#4. 분류기 추가. \n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "#model.summary()\n",
    "#5. 모델 컴파일 \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#6. 학습  batch_size  = 32, epochs= 3 \n",
    "model.fit(train_images, train_labels, batch_size=32, epochs=3, validation_split=0.1)\n",
    "\n",
    "#7. 평가  \n",
    "loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f'Test loss: {loss}, Test accuracy: {accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
