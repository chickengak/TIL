{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bd83a12",
   "metadata": {},
   "source": [
    "### * RNN 주요 레이어 종류\n",
    "#### (1) SimpleRNN :가장 간단한 형태의 RNN레이어, 활성화 함수로 tanh가 사용됨(tanh: -1 ~ 1 사이의 값을 반환)\n",
    "#### (2) LSTM(Long short Term Memory) : 입력 데이터와 출력 사이의 거리가 멀어질수로 연관 관계가 적어진다(Long Term Dependency,장기의존성 문제), LSTM은 장기 의존성 문제를 해결하기 위해 출력값외에 셀상태(cell state)값을 출력함, 활성화 함수로 tanh외에 sigmoid가 사용됨\n",
    "#### (3) GRU(Gated Recurent Unit) : 뉴욕대 조경현 교수 등이 제안, LSTM보다 구조가 간단하고 성능이 우수함\n",
    "\n",
    "<<참고 : https://colah.github.io/posts/2015-08-Understanding-LSTMs/ >>\n",
    "https://link.springer.com/article/10.1007/s11063-009-9096-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d39db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, GRU\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9349ed99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 4, 1) (6,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 4, 1), dtype=float32, numpy=\n",
       "array([[[0.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [3.]],\n",
       "\n",
       "       [[1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.]],\n",
       "\n",
       "       [[2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.]],\n",
       "\n",
       "       [[3.],\n",
       "        [4.],\n",
       "        [5.],\n",
       "        [6.]],\n",
       "\n",
       "       [[4.],\n",
       "        [5.],\n",
       "        [6.],\n",
       "        [7.]],\n",
       "\n",
       "       [[5.],\n",
       "        [6.],\n",
       "        [7.],\n",
       "        [8.]]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequence data\n",
    "x = np.array([[0,1,2,3],\n",
    "              [1,2,3,4],\n",
    "              [2,3,4,5],\n",
    "              [3,4,5,6],\n",
    "              [4,5,6,7],\n",
    "              [5,6,7,8]],dtype=np.float32)\n",
    "\n",
    "x_data = tf.reshape(x, (-1,4,1))  # (6,4,1)\n",
    "\n",
    "y_data = np.array([4,5,6,7,8,9],dtype=np.float32)\n",
    "\n",
    "print(x_data.shape,y_data.shape)\n",
    "# print(type(x_data),type(y_data))\n",
    "x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d132083",
   "metadata": {},
   "source": [
    "### [1] SimpleRNN\n",
    "#### 가장 간단한 형태의 RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79baf00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ALT\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\simple_rnn.py:130: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ALT\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 4, 300)            90600     \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 300)               180300    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 301       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271201 (1.03 MB)\n",
      "Trainable params: 271201 (1.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Q1)  SimpleRNN모델 구현하자.  \n",
    "#X :  (6,4,1)   reshape한 데이터\n",
    "# Wx : (1,300 )   ,  입력 가중치   (입력차원, 뉴런) = 파라미터 개수 = 1*300=300개\n",
    "# Wh (300,300) ,  숨겨진 상태 가중치     (유닛개수, 숨겨진 상태) 그래서 파라미터 수는 300*300=90,000\n",
    "# b (300) , param 90600      = Wx 300 + Wh 90,000 + b 300 = 90,600\n",
    "# OUt (None, 4, 300)  \n",
    "model = Sequential([\n",
    "    SimpleRNN(units=300, return_sequences=True, input_shape=[4,1]),\n",
    "    \n",
    "#X :  (None, 4, 300)   \n",
    "# Wx : (300,300 )   , Wh (300,300) , b (300) , param 180300   , OUt (None,300)  \n",
    "    SimpleRNN(units=300),\n",
    "    Dense(1)      # 출력 차원이 1, 가중치 형태 = (300, 1) = 300 + 1 = 301\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27e5618",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_data, y_data, epochs=100, verbose=1)\n",
    "print(model.predict(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd8942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(np.array([[[6.],[7.],[8.],[9.]]])))\n",
    "print(model.predict(np.array([[[-1.],[0.],[1.],[2.]]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5a8781",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd4ffa4",
   "metadata": {},
   "source": [
    "### [2] LSTM(Long short Term Memory)\n",
    "#### 입력 데이터와 출력 사이의 거리가 멀어질수로 연관 관계가 적어진다(Long Term Dependency,장기의존성 문제)\n",
    "#### LSTM은 장기 의존성 문제를 해결하기 위해 출력값외에 셀상태(cell state)값을 출력함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e64f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2) RNN 순환 신경망 구현  : LSTM\n",
    "model = Sequential([   \n",
    " #X :  (6,4,1) \n",
    "# Wx : (1,4*300 )   , Wh (300,4*300) , b (4*300) , param  4*90600      , OUt (None, 4, 300)\n",
    "    LSTM(units=300, return_sequences=True, input_shape=[4,1]),  \n",
    "    \n",
    "  #X :  None, 4, 300\n",
    "# Wx : (300,4*300 )   , Wh (300,4*300) , b (4*300) , param  4*180300     , OUt   (None, 300) \n",
    "    LSTM(units=300),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249e2ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 및 예측\n",
    "model.fit(x_data,y_data,epochs=100,verbose=1)\n",
    "print(model.predict(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec2ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습되지 않은 입력 데이터에 대한 예측 결과\n",
    "print(model.predict(np.array([[[6.],[7.],[8.],[9.]]])))\n",
    "print(model.predict(np.array([[[-1.],[0.],[1.],[2.]]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8ee5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_data,y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca63f56e",
   "metadata": {},
   "source": [
    "### [3] GRU(Gated Recurent Unit)\n",
    "#### 뉴욕대 조경현 교수 등이 제안, LSTM보다 구조가 간단하고 성능이 우수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f214bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN 순환 신경망 구현  : GRU\n",
    "model = Sequential([\n",
    "    GRU(units=300, return_sequences=True, input_shape=[4,1]),\n",
    "    GRU(units=300),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82da4f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 및 예측\n",
    "model.fit(x_data,y_data,epochs=100,verbose=1)\n",
    "print(model.predict(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0362514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습되지 않은 입력 데이터에 대한 예측 결과\n",
    "print(model.predict(np.array([[[6.],[7.],[8.],[9.]]])))\n",
    "print(model.predict(np.array([[[-1.],[0.],[1.],[2.]]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3774ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39705245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
