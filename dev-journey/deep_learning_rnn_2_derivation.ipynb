{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ca778d",
   "metadata": {},
   "source": [
    "### * RNN 주요 레이어 종류\n",
    "#### (1) SimpleRNN :가장 간단한 형태의 RNN레이어, 활성화 함수로 tanh가 사용됨(tanh: -1 ~ 1 사이의 값을 반환)\n",
    "#### (2) LSTM(Long short Term Memory) : 입력 데이터와 출력 사이의 거리가 멀어질수로 연관 관계가 적어진다(Long Term Dependency,장기의존성 문제), LSTM은 장기 의존성 문제를 해결하기 위해 출력값외에 셀상태(cell state)값을 출력함, 활성화 함수로 tanh외에 sigmoid가 사용됨\n",
    "#### (3) GRU(Gated Recurent Unit) : 뉴욕대 조경현 교수 등이 제안, LSTM보다 구조가 간단하고 성능이 우수함\n",
    "\n",
    "<<참고 : https://colah.github.io/posts/2015-08-Understanding-LSTMs/ >>\n",
    "https://link.springer.com/article/10.1007/s11063-009-9096-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5b6f445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ALT\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, GRU\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56c8cb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 4, 1) (6,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 4, 1), dtype=float32, numpy=\n",
       "array([[[0.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [3.]],\n",
       "\n",
       "       [[1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.]],\n",
       "\n",
       "       [[2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.]],\n",
       "\n",
       "       [[3.],\n",
       "        [4.],\n",
       "        [5.],\n",
       "        [6.]],\n",
       "\n",
       "       [[4.],\n",
       "        [5.],\n",
       "        [6.],\n",
       "        [7.]],\n",
       "\n",
       "       [[5.],\n",
       "        [6.],\n",
       "        [7.],\n",
       "        [8.]]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequence data\n",
    "x = np.array([[0,1,2,3],\n",
    "              [1,2,3,4],\n",
    "              [2,3,4,5],\n",
    "              [3,4,5,6],\n",
    "              [4,5,6,7],\n",
    "              [5,6,7,8]],dtype=np.float32)\n",
    "\n",
    "x_data = tf.reshape(x, (-1,4,1))  # (6,4,1)\n",
    "\n",
    "y_data = np.array([4,5,6,7,8,9],dtype=np.float32)\n",
    "\n",
    "print(x_data.shape,y_data.shape)\n",
    "# print(type(x_data),type(y_data))\n",
    "x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815faa3a",
   "metadata": {},
   "source": [
    "### [1] SimpleRNN\n",
    "#### 가장 간단한 형태의 RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dbacc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ALT\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\simple_rnn.py:130: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ALT\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 4, 300)            90600     \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 300)               180300    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 301       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271201 (1.03 MB)\n",
      "Trainable params: 271201 (1.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Q1)  SimpleRNN모델 구현하자.  \n",
    "\n",
    "model = Sequential([\n",
    "# X  : (6, 4, 1)   reshape한 데이터\n",
    "# Wx : (1, 300)   ,  (입력차원 1, 뉴런 300개) 입력 가중치 = 파라미터 개수 = 1*300=300개\n",
    "# Wh : (300, 300) ,  (유닛개수, 숨겨진 상태)  숨겨진 상태의 가중치.  그래서 파라미터 수는 300*300=90,000\n",
    "# b  : (300) ,\n",
    "# 총 param : 90600      = Wx 300 + Wh 90,000 + b 300 = 90,600\n",
    "# OUt (None, 4, 300)  \n",
    "    SimpleRNN(units=300, return_sequences=True, input_shape=[4,1]),\n",
    "    \n",
    "# X  : (None, 4, 300)   \n",
    "# Wx : (300, 300),  앞 레이어에서 유닛 300개로 받았기 때문에, 입력차원이 300이다.\n",
    "# Wh : (300, 300),      위와 같음\n",
    "# b  : (300),\n",
    "# 총 param : 180300   , OUt (None, 300)  \n",
    "    SimpleRNN(units=300),\n",
    "    Dense(1)      # 출력 차원이 1, 가중치 형태 = (300, 1) = 300*1 + 1 = 301\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43de4c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\ALT\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step - loss: 53.7663\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.8309\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.8359\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.6183\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.8950\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6185\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.0275\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.6434\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.4279\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.0649\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.0392\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.8203\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0773\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3501\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3804\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1570\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8400\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6495\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7112\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8946\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.9183\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7279\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5245\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4662\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5261\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5901\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5779\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4895\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3931\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3674\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4147\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4398\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3765\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2826\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2424\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2551\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2600\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2198\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1595\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1331\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1502\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1549\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1171\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0823\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0849\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0961\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0808\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0526\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0479\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0597\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0506\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0296\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0291\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0376\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0303\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0186\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0233\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0292\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0211\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0176\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0243\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0238\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0175\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0194\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0226\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0180\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0162\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0193\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0176\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0145\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0163\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0165\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0136\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0139\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0146\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0124\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0117\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0124\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0110\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0098\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0103\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0096\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0085\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0089\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0086\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0077\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0079\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0079\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0072\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0073\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0073\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0067\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0067\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0067\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0063\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0062\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0062\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0058\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0057\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 504ms/step\n",
      "[[4.01417  ]\n",
      " [4.96672  ]\n",
      " [5.9981103]\n",
      " [7.088033 ]\n",
      " [8.073884 ]\n",
      " [8.867755 ]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_data, y_data, epochs=100, verbose=1)\n",
    "print(model.predict(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ad0df65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n",
      "[[9.459349]]\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "[[0.7824381]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(np.array([[[6.],[7.],[8.],[9.]]])))\n",
    "print(model.predict(np.array([[[-1.],[0.],[1.],[2.]]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbec4fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 690ms/step - loss: 0.0053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.005334893707185984"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd82adbc",
   "metadata": {},
   "source": [
    "### [2] LSTM(Long short Term Memory)\n",
    "#### 입력 데이터와 출력 사이의 거리가 멀어질수로 연관 관계가 적어진다(Long Term Dependency,장기의존성 문제)\n",
    "#### LSTM은 장기 의존성 문제를 해결하기 위해 출력값외에 셀상태(cell state)값을 출력함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d327f3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 4, 300)            362400    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 300)               721200    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 301       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1083901 (4.13 MB)\n",
      "Trainable params: 1083901 (4.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Q2) RNN 순환 신경망 구현  : LSTM\n",
    "model = Sequential([   \n",
    " #X :  (6,4,1) \n",
    "# Wx : (1,4*300 )   , Wh (300,4*300) , b (4*300) , param  4*90600      , OUt (None, 4, 300)\n",
    "    LSTM(units=300, return_sequences=True, input_shape=[4,1]),  \n",
    "    \n",
    "  #X :  None, 4, 300\n",
    "# Wx : (300,4*300 )   , Wh (300,4*300) , b (4*300) , param  4*180300     , OUt   (None, 300) \n",
    "    LSTM(units=300),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c50fc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 44.5882\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 38.7813\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 32.9089\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 26.3858\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 19.0041\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 11.1793\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.4054\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.3605\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8046\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.7651\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.9216\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.1851\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.0142\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3639\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5657\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5024\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8653\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.3513\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7541\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9739\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9900\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8289\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.5424\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1931\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8443\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5523\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3580\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2805\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3121\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4194\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5529\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6621\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7119\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6919\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6157\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5118\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4112\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3372\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3005\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2996\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3241\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3597\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3926\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4128\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4151\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3999\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3715\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3370\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3041\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2792\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2658\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2639\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2702\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2792\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2858\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2860\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2789\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2661\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2511\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2374\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2278\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2231\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2228\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2247\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2265\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2266\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2239\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2186\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2120\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2054\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2001\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1968\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1953\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1949\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1946\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1935\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1913\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1880\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1843\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1809\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1781\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1762\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1750\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1739\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1726\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1709\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1686\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1661\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1636\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1614\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1596\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1581\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1566\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1551\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1534\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1515\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1495\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1476\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1458\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1442\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "[[3.3839843]\n",
      " [5.1063867]\n",
      " [6.3788466]\n",
      " [7.3086944]\n",
      " [7.9998574]\n",
      " [8.523838 ]]\n"
     ]
    }
   ],
   "source": [
    "# 학습 및 예측\n",
    "model.fit(x_data,y_data,epochs=100,verbose=1)\n",
    "print(model.predict(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03e2743a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[8.927953]]\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "[[1.2589666]]\n"
     ]
    }
   ],
   "source": [
    "# 학습되지 않은 입력 데이터에 대한 예측 결과\n",
    "print(model.predict(np.array([[[6.],[7.],[8.],[9.]]])))\n",
    "print(model.predict(np.array([[[-1.],[0.],[1.],[2.]]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2f7f676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 996ms/step - loss: 0.1427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1427234411239624"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_data,y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc223d3",
   "metadata": {},
   "source": [
    "### [3] GRU(Gated Recurent Unit)\n",
    "#### 뉴욕대 조경현 교수 등이 제안, LSTM보다 구조가 간단하고 성능이 우수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55236001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 4, 300)            272700    \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 300)               541800    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 301       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814801 (3.11 MB)\n",
      "Trainable params: 814801 (3.11 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RNN 순환 신경망 구현  : GRU\n",
    "model = Sequential([\n",
    "    GRU(units=300, return_sequences=True, input_shape=[4,1]),\n",
    "    GRU(units=300),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2f0e7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 46.8683\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 30.1131\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 16.6262\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 6.3786\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.9285\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.3534\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 6.2152\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 6.5697\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.4283\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.0281\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5887\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2671\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6680\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.2982\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.7987\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.0046\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.9046\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5758\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1328\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6921\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3486\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1586\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1314\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2301\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3864\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5255\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5926\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5695\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4730\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3413\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2154\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1252\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0830\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0853\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1174\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1608\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1988\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2198\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2190\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1984\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1645\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1264\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0931\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0711\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0631\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0677\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0803\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0945\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1047\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1074\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1022\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0912\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0781\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0666\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0594\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0573\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0594\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0638\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0684\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0712\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0714\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0690\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0649\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0604\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0567\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0545\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0542\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0552\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0568\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0581\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0585\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0579\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0564\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0546\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0530\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0520\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0516\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0518\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0522\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0526\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0526\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0522\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0515\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0507\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0500\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0495\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0492\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0492\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0492\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0491\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0490\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0486\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0482\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0477\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0473\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0470\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0468\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0467\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0466\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0464\n",
      "1/1 [==============================] - 1s 797ms/step\n",
      "[[3.6501045]\n",
      " [5.017257 ]\n",
      " [6.195198 ]\n",
      " [7.192307 ]\n",
      " [8.026705 ]\n",
      " [8.720185 ]]\n"
     ]
    }
   ],
   "source": [
    "# 학습 및 예측\n",
    "model.fit(x_data,y_data,epochs=100,verbose=1)\n",
    "print(model.predict(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ee5b6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[9.294562]]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "[[2.1034653]]\n"
     ]
    }
   ],
   "source": [
    "# 학습되지 않은 입력 데이터에 대한 예측 결과\n",
    "print(model.predict(np.array([[[6.],[7.],[8.],[9.]]])))\n",
    "print(model.predict(np.array([[[-1.],[0.],[1.],[2.]]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb96990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7ddc97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
