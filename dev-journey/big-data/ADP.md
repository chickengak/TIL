# 데이터의 이해

### 데이터의 특성
- 존재적 특성: 객관적 사실 (Fact)
- 당위적 특성: 추록, 예측, 전망, 추정을 위한 근거 (Basis)

### 데이터의 유형
정형 데이터 vs 반정형 데이터 vs 비정형 데이터

정성적 데이터 vs 정량적 데이터
- 정성적 데이터(Qualitative Data): 언어, 문자
- 정량적 데이터(Quantitative Data): 수치, 도형, 기호

암묵지 vs 형식지
- 암묵지(Tacit Knoewledge): 사회적으로 중요하지만, 다른 사람에게 공유되기 어려움
    - 개인에게 축적된 **내면화(Internalization)** 된 지식 → 조직의 지식으로 **공통화(Socialization)**
- 형식지(Explicit Knowledge): 전달과 공유가 용이함
    - 언어, 기호, 숫자로 **표출화(Externalization)** 된 지식 → 개인의 지식으로 **연결화(Combination)**

### DIKW 피라미드
- 데이터(Data)
- 정보(Information): 데이터의 상관관계와 패턴을 인지하여 의미를 부여.
- 지식(Knowledge): 정보로 예측한 결과물
- 지혜(Wisdom): 근본 원리에 대한 이해 후, 도출되는 창의적인 아이디어


### 데이터베이스의 특징
- 통합된 데이터(Intergrated Date): 데이터가 중복되지 않음.
- 저장된 데이터(Stored Data)
- 공용 데이터(Shared Data)
- 변화되는 데이터(Changable Data)

### 데이터베이스의 종류
1990년대 기업내부 DB
- OLTP (On-Line Transaction Processing)
- OLAP (On-Line Analytical Processing)

2000년대 기업내부 DB
- CRM (Customer Relationship Management)
- SCM (Supply Chain Managemet)

제조분야
- ERP
- BI
- CRM
- RTE

금융분야
- EAI
- EDW

유통분야
- KMS
- RFID

사회기반 DB
- EDI
- VAN
- CALS

<br>
<br>

# 빅데이터

## 관점에 따른 빅데이터의 정의
1. 3V로 요약되는 데이터 자체의 특성 변화에 초점을 맞춘 좁은 범위의 정의
2. 데이터 자체뿐만 아니라 처리, 분석 기술적 변화까지 포함되는 중간 범위의 정의
3. 인재, 조직 변화까지 포함한 넓은 관점에서의 정의

| 데이터 변화 | 기술 변화 | 인재, 조직 변화 |
|---|---|---|
| Volume | 데이터 처리, 저장, 분석 기술 및 아키텍처 | DS 같은 새로운 인재 필요 |
| Velocity | 클라우드 컴퓨팅 활용 | 데이터 중심 조직 |
| Variety |  |  |


### 3V + 4V
- Volume + Velocity + Variety
- Value, Veracity, Validity, Volatility

### 빅데이터의 비유
- 산업혁명의 석탄과 철
- 21세기의 운유
- 렌즈
- 플랫폼

### 빅데이터가 만든 변화
- 사전처리 ▶ 사후처리
- 표본조사 ▶ 전수조사
- 질　　　 ▶ 양
- 인과관계 ▶ 상관관계

### 빅데이터의 가치 산정이 어려운 이유
- 데이터 활용방식: 데이터 활용이 일반화 되면서, 특정 데이터를 누가 언제 어디서 어떻게 활용할 지 알 수가 없다.
- 새로운 가치 창출: 기존에 없던 가치를 창출하면 측정이 어려움
- 분석 기술 발전: 기술 발전으로 가치가 없던 데이터에서 가치를 만들기도 함

### 빅데이터 활용 기본 테크닉
- 연관 규칙 학습
- 유형 분석
- 유전자 알고리즘
- 기계 학습
- 회귀 분석
- 감정 분석
- 소셜 네트워크 분석 (=사회관계망 분석)


## 빅데이터의 위기와 통제 방안
1. 사생활 침해 　 ▶ 동의에서 책임으로: 개인정보를 사용하는 사용자의 책임으로
2. 책인 원칙 훼손 ▶ 결과 기반 책임 원칙 고수
3. 데이터 오용 　 ▶ 알고리즘 접근 허용

<br>
<br>

# 빅데이터 분석과 전략 인사이트

### 빅데이터 회의론의 원인
1. 투자효과를 거두지 못했던 부정적 학습효과 (과거의 CRM)
2. 빅데이터 성공사례가 기존 분석 프로젝트를 포함한 경우

## 일차원적인 분석 vs 전략도출 위한 가치기반 분석

표생략

### 일차적인 분석
- 일차적인 분석으로도 상당한 효과를 얻을 수도 있다.
- 허나 큰 변화에 제대로 대응하여 새로운 기회를 포착하기는 어렵다.

### 전략도출 가치기반 분석
- 사업성과를 견인하는 요소와 사업 차별화를 꾀할 기회에 대해 전략적 인사이트를 주는 가치기반 분석단계를 해야함.
- 일차적인 분석을 통해 분석 경험을 쌓은 후, 분석의 활용 범위를 더 넓고 전략적으로 변화시켜야 함.
- 전략적 통찰로 분석해야 사업에 중요한 기회를 발굴하고, 주요 경영진의 지원을 얻을 수 있으며, 이를 통해 강력한 모멘텀을 만들 수 있다.

### 전략 인사이트 도출을 위한 데이터 사이언티스트의 요구 역량
데이터 사이언스의 3 영역
- 분석적 영역, 비즈니스 컨설팅 영역, 데이터 처리와 관련된 IT 영역

Hard Skill
 - 빅데이터에 대한 이론적 지식, 분석 기술에 대한 숙련

Soft Skill
- 통찰력 있는 분석, 설득력 있는 전달, 사람과 협력

## 빅데이터 패러다임의 변화
Digitalization → Connection → Agency

<br>
<br>

# 기타 빅데이터 상식

### DBMS의 종류
1. RDBMS
2. 객체지향 DBMS
3. 네트워크 DBMS: 레코드들이 노드로, 레코드 간의 관계는 간선으로 표현. 그래프 기반
4. 계층형 DBMS: 트리구조 기반

### 데이터베이스의 설계 절차
요구사항 분석 → 개념적 설계 → 논리적 설계 → 물리적 설계 → 구현

### 데이터 웨어하우스, ETL, 데이터 레이크

### 개인정보 비식별 기술
- 데이터 마스킹
- 가명 처리
- 총계 처리
- 데이터값 삭제
- 데이터 범주화

### 데이터 무결성
- 개체 무결성
- 참조 무결성
- 범위 무결성


<br>
<br>

----

<br>
<br>

# 데이터 처리 프로세스

## ETL
- 데이터 원천 → 운영 데이터 스토어 (ODS) → 데이터 웨어하우스 (DW) → 데이터 마트 (DM) 처럼 데이터가 이동하고 변환되고 적재되는 과정에서 사용.
- 데이터 통합(Data Integration), 데이터 이동(Data Migration), 마스터 데이터 관리(MDM, Master Data Management)에 걸쳐 폭넓게 사용
- 정기적으로 재사용이 가능한 컴포넌트들.
- 대용량 데이터를 처리하기 위한 MPP(Massively Parallel Processing)를 지원
- 다양한 시스템들 간의 대용량 데이터 교환. 복잡도가 높은 비즈니스 룰 적용이 필요한 데이터 교환.
- Batch(일괄) ETL, Real Time(실시간) ETL 로 나뉨.

### ODS
- 다양한 Source에서 데이터를 추출하고 통합한 데이터베이스
- 일반적으로 실시간(Real time) 혹은 근접실시간(Near real time) 트랜잭션 데이터, 원자성을 지닌 하위 수준 데이터를 저장하귀 위해 설계됨.

**ODS 구성 단계**
1. 인터페이스 단계
2. 데이터 스테이징 단계
    - Source에서 트랜잭션 데이터들을 추출하여 스테이징 테이블에 저장
3. 데이터 프로파일링 단계
    - 범위·도메인·유일성 확보 등의 규칙을 기준으로 데이터 품질 점검을 하는 단계
4. 데이터 클렌징 단계
    - 프로파일링 단계에서 식별된 오류 데이터들을 수정하는 단계
5. 데이터 인테그레이션 단계
    - 수정된 데이터를 ODS내의 단일 통합 테이블에 적재
6. 익스포트 단계
    - 익스포트 규칙과 보안 규칙을 반영한 익스포트 ETL 기능을 수행해 익스포트 테이블을 생성.

### DW
ODS를 통해 정제 및 통합된 데이터가 데이터 분석과 보고서 생성을 위해 적재되는 저장소.

**데이터 웨어하우스 특징**
- 주제 중심성
- 영속성·비휘발성
- 통합성
- 시계열성

**데이터 웨어하우스의 테이블 모델링 기법**

- 스타 스키마
    - 사실 테이블(Fact Table)은 보통 제 3정규형, 차원 테이블(Dimensional Table)은 보통 비정규화된 제 2정규형
    - 가장 단순. 비정규화에 따른 데이터 중복으로 인해 적재시 시간이 오래 걸림.
- 스노우 플레이크 스키마
    - 차원 테이블도 제 3정규형
    - 적재시간은 짧으나, 복잡성이 증가하고 조인 테이블의 개수가 증가하고 쿼리 작성 난이도가 상승함.
### ODS와 DW 비교
표

## CDC
Change Data Capture  
- 데이터 변경을 식별해서 처리함.
- 실시간 혹은 근접 실시간 데이터 통합을 기반으로 하는 저장소에 쓰임.

### CDC 기법
- Time Stamp on Rows
- Version Numberes on Rows
- Status on Rows
- Time/Version/Status on Rows
- Triggers on Tables
- Event Programming
- Log Scanner on Database

### CDC 구현 방식
- 푸시 방식
- 풀 방식

## EAI
Enterprise Application Integration  
- 비즈니스 프로세스를 중심으로 기업 내 각종 어플리케이션간의 상호 연동이 가능하도록 통합하는 솔루션.
- ETL은 배치 프로세스 중심이고, 실시간 혹은 근접 실시간 처리 중심.

Hub and Spoke 방식
- 기존의 포인트 투 포인트 방식은 복잡하고 비용이 비쌈.
- ETL과 CDC는 운영 데이터와 분석을 위한 데이터베이스가 구분되지만, EAI는 다수 정보 시스템의 데이터를 중앙의 허브가 연계하고 통합하는 기법.

### EAI 구성요소
- 어댑터(Adapter)
- 버스(Bus)
- 브로커(Broker)
- 트랜스포머(Transformer)

### EAI 구현 유형
- Mediation (Intra-Communication)
- Federation (Inter-Communication)

### EAI 장점
- 비용 절감
- 개발 및 발전 기반 확보
- 협력사·고객과의 상호 협력 프로세스 연계 가능
- 분리된 시스템간의 데이터 동기화
- 테이터 표준화 제공 가능

### EAI와 ESB 비교
표

## 데이터 통합 및 연계 기법
흠

## 대용량 비정형 데이터 처리 방법

### 대용량 비정형 데이터 수집 시스템의 특징
1. 초고속 수집 성능과 확장성
    - 수많은 서비스에서 발생하는 실시간 데이터를 놓치지 않아야 하고, 쉽게 확장 가능해야 함.
2. 데이터 전송 보장 메커니즘
    - 성능과 안정성이라는 트레이드 오프가 존재함.
3. 다양한 수집과 저장 플러그인
    - 로그 수집 시스템: 아파치 Flume-NG, 페이스북 Scribe, 아파치 Chukwa
4. 인터페이스 상속을 통한 어플리케이션 기능 확장

### 대규모 분산 병렬 처리
**하둡**
- 대규모 분산 병렬 처리의 업계 표준인 맵리듀스와 분산 파일시스템인 HDFS를 핵심 구성요소인 플랫폼 기술

**하둡의 특징**
1. 선형적인 성능과 용량 확장
    - 클러스터의 서버 수는 제한이 없고, 통상적으로 최소 5대 정도.
    - 비공유 분산 아키텍처 시스템이기 때문에, 서버를 추가함에 따라 비례하게 연산기능과 저장기능이 향상됨.
2. 고장 감내성
    - HDFS에 3중 복제로 저장
    - 맵리듀스 수행 중 장애가 생기면, 자동으로 장애가 발생한 태스크만 다른 서버에서 재실행 함.
3. 핵심 비즈니스 로직에 집중

**하둡 에코 시스템**


<br>
<br>

----

<br>
<br>
