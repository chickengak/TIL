{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dac63b4",
   "metadata": {},
   "source": [
    "콜백함수란? 어떤 함수를 수행 시 그 함수에서 사용자가 지정한 함수를 호출하는 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cf95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ▶ Step 1. EarlyStopping을 테스트할 데이터 만들기 \"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "data, target = make_circles(n_samples=2000, noise=0.2, factor=0.3)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.2, stratify=target)\n",
    "\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect='equal', xlim=(-2, 2), ylim=(-2, 2))\n",
    "ax.scatter(x_train[y_train == 0, 0], x_train[y_train == 0, 1], marker=\"o\")\n",
    "ax.scatter(x_train[y_train == 1, 0], x_train[y_train == 1, 1], marker=\"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aba0976",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ▶ Step 2. 간단한 신경망을 만들어서 학습시키자 \"\"\"\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(16, activation='tanh', input_shape=(2,)),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=[x_test, y_test])\n",
    "\n",
    "#Q4) 손실함수와 정답률의 변화를 시각화 \n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "ax = fig.add_subplot(1, 2, 1, title=\"loss\")\n",
    "ax.plot(hist.epoch, hist.history[\"loss\"], label=\"train_loss\")\n",
    "ax.plot(hist.epoch, hist.history[\"val_loss\"], linestyle=\"-.\", label=\"val_loss\")\n",
    "ax.legend()\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2, title=\"acc\")\n",
    "ax.plot(hist.epoch, hist.history[\"acc\"], label=\"train_acc\")\n",
    "ax.plot(hist.epoch, hist.history[\"val_acc\"], linestyle=\"-.\", label=\"val_acc\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eff732f",
   "metadata": {},
   "source": [
    "###  tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')\n",
    " \n",
    "    값의 변화가 정지했을 때에 훈련을 종료하는 목적을 가진 메소드 \n",
    "\n",
    "\n",
    "- monitor : 모니터링 할 값.\n",
    "- min_delta : 모니터링 할 값에 대해 개선으로 결정되는 최소 변화 값. 즉, min_delta보다 절대치의 변화가 작으면 개선되어 있지 않다고 판단\n",
    "- patience : 여기에 지정된 에포크 수 동안 (감시하는 값에) 개선이 없으면 훈련이 중지\n",
    "- verbose : 중복 모드.\n",
    "- mode : {auto, min, max} 중 하나가 선택. \n",
    "  - min : 모니터링 할 값의 감소가 중지되면 훈련이 종료\n",
    "  - max : 모니터링 할 값의 증가가 중지되면 훈련이 종료. \n",
    "  - auto:  자동으로 모니터링되는 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8e172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "EarlyStopping(\n",
    "    monitor='val_loss',   # 모니터링 지표값.\n",
    "    min_delta=0,        # 최소 변화량    0.001\n",
    "    patience=0,         # 지정된 에폭 수 동안 모니터링 지표의 개선이 없을 때, 학습을 중지. ex) 10을 주면 10에폭동안 개선이 없으면 중지됨.\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,      # 지정된 수치값보다 개선되지 않으면 학습을 종료\n",
    "    restore_best_weights=False,   # 마지막 학습된 가중치가 유지\n",
    "    start_from_epoch=0     # early stop을 시작할 에폭 번호.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ef1537",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ▶ Step 3. EarlyStopping을 넣어 학습시켜 보자 \"\"\"\n",
    "model = Sequential([\n",
    "    Dense(16, activation='tanh', input_shape=(2,)),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               min_delta=0.001,\n",
    "                               patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=[x_test, y_test],\n",
    "                 callbacks=[early_stopping])\n",
    "# monitor에 설정된 값이 patience 값의 횟수를 계속해서 min_delta 이상 개선되지 않으면 학습이 중지\n",
    "              # monitor에는 'val_loss' 외에 'val_acc'등도 설정할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941eb45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4) 손실함수와 정답률의 변화를 시각화 \n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "ax = fig.add_subplot(1, 2, 1, title=\"loss\")\n",
    "ax.plot(history.epoch, history.history[\"loss\"], label=\"train_loss\")\n",
    "ax.plot(history.epoch, history.history[\"val_loss\"], linestyle=\"-.\", label=\"val_loss\")\n",
    "ax.legend()\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2, title=\"acc\")\n",
    "ax.plot(history.epoch, history.history[\"acc\"], label=\"train_acc\")\n",
    "ax.plot(history.epoch, history.history[\"val_acc\"], linestyle=\"-.\", label=\"val_acc\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddffce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답이 특정값 이상됐을 떄 중단하고 싶으면. (90%)\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "early_stopping =  EarlyStopping(\n",
    "                            monitor='val_acc',\n",
    "                            min_delta=0.0001,\n",
    "                            patience=5, verbose=1, restore_best_weights=True,\n",
    "                            mode = 'max'\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=16,\n",
    "                    validation_data=[X_test, y_test],\n",
    "                    callbacks=[early_stopping] \n",
    "            )# monitor에 설정된 값이 patience 값의 횟수를 계속해서 min_delta 이상 개선되지 않으면 학습이 중지\n",
    "              # monitor에는 'val_loss' 외에 'val_acc'등도 설정할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b4be32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9454c56f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
